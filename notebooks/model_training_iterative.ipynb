{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Setting logging level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or '3' to additionally suppress all warnings\n",
    "\n",
    "# TensorFlow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, MaxPooling2D, BatchNormalization, Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# In this notebook, I train four different Keras Sequential models using a cleaned dataset. The models, named model_1_concept, model_2_best, model_3_best_nodropout, and model_4_best_nodropout_nobatchn, \n",
    "# were developed through experimentation and adjustments based on the initial concept and literature recommendations for convolutional neural networks (CNN).\n",
    "\n",
    "# The code begins with importing necessary modules and creating ImageDataGenerators and flow_from_directory functions for both the training and test sets. \n",
    "# The model architectures are specified in JSON files, which are read by the code to iteratively build each Keras model. This allows easy iteration over different models and manual adjustments to optimizers and color modes (RGB or grayscale). \n",
    "# The training history for each model is saved, enabling tracking and visualization of performance and learning. \n",
    "# Additionally, model architectures are saved in the \"diagram\" folder, checkpoint files are saved on improved epochs, and final models are saved as h5 files.\n",
    "\n",
    "# Examples of saved file formats include:\n",
    "#     History: model_1_concept_adam_grayscale_32_augment_history.json\n",
    "#     Final model (not included on Git due to size): model_2_best_rmsprop_rgb_512_augment_final.h5\n",
    "#     Checkpoint: model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n",
    "\n",
    "# For practicality, only the best-performing model is saved in a dedicated \"models/best_model\" folder, including both the architecture (JSON file) and weights (h5 file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92968 images belonging to 7 classes.\n",
      "Found 17356 images belonging to 7 classes.\n",
      "Total images in training set: 92968\n",
      "Total images in test set: 17356\n"
     ]
    }
   ],
   "source": [
    "# Image Specifications\n",
    "folder_path = \"../dataset/MMAFEDB/\"\n",
    "image_dimension = (48, 48)\n",
    "image_depth = 3\n",
    "image_color_mode = 'rgb'\n",
    "batch_size = 512\n",
    "augment = 'augment'\n",
    "\n",
    "# Data Augmentation for Training Set\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Only rescaling for Validation Set\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Training flow_from_directory\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    folder_path + \"train\",\n",
    "    target_size=image_dimension,\n",
    "    color_mode=image_color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Testing flow_from_directory\n",
    "test_set = datagen_val.flow_from_directory(\n",
    "    folder_path + \"test\",\n",
    "    target_size=image_dimension,\n",
    "    color_mode=image_color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Get the total number of images in the training set\n",
    "total_images_train = train_set.n\n",
    "print(\"Total images in training set:\", total_images_train)\n",
    "# Get the total number of images in the test set\n",
    "total_images_test = test_set.n\n",
    "print(\"Total images in test set:\", total_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found JSON config files in models: ['model_1_concept.json', 'model_2_best.json', 'model_3_best_nodropout.json', 'model_4_best_nodroupout_nobatchn.json']\n",
      "\n",
      "########################################\n",
      "Using File model_1_concept.json to train model!\n",
      "########################################\n",
      "\n",
      "JSON Loaded: {'Conv2D_1': {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}, 'MaxPooling2D_1': {'pool_size': 2}, 'Conv2D_3': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Conv2D_4': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'MaxPooling2D_2': {'pool_size': 2}, 'Conv2D_5': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Conv2D_6': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'MaxPooling2D_3': {'pool_size': 2}, 'Conv2D_7': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Conv2D_8': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Flatten': {}, 'Dense_1': {'units': 512, 'activation': 'relu'}, 'Dense_2': {'units': 512, 'activation': 'relu'}, 'BatchNormalization_7': {}, 'Dense_3': {'units': 7, 'activation': 'softmax'}}\n",
      "\n",
      "Creating Sequential Model ...\n",
      "Added Conv2D_1: {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}\n",
      "Added MaxPooling2D_1: {'pool_size': 2}\n",
      "Added Conv2D_3: {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Conv2D_4: {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added MaxPooling2D_2: {'pool_size': 2}\n",
      "Added Conv2D_5: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Conv2D_6: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added MaxPooling2D_3: {'pool_size': 2}\n",
      "Added Conv2D_7: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Conv2D_8: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Flatten: {}\n",
      "Added Dense_1: {'units': 512, 'activation': 'relu'}\n",
      "Added Dense_2: {'units': 512, 'activation': 'relu'}\n",
      "Added BatchNormalization_7: {}\n",
      "Added Dense_3: {'units': 7, 'activation': 'softmax'}\n",
      "\n",
      "Optimizers to select from: ['adam', 'rmsprop', 'sgd']\n",
      "\n",
      "Selected Optimizer for training: rmsprop\n",
      "Loss function used: categorical_crossentropy\n",
      "Metrics used: [['accuracy']]\n",
      "The model has been compiled, showing summary below!\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 23, 23, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 23, 23, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4708615 (17.96 MB)\n",
      "Trainable params: 4707591 (17.96 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n",
      "Saving plot_model figure of current model layout to ../models/training/diagram/model_1_concept_rmsprop_rgb_512_augment_diagram.png\n",
      "\n",
      "Setting up checkpoint file for incremental validation accuracy improvements\n",
      "********************** Model training started! ********************\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.4121 - accuracy: 0.4855\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44437, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 81s 365ms/step - loss: 1.4121 - accuracy: 0.4855 - val_loss: 1.6220 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fox/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 0s - loss: 1.1933 - accuracy: 0.5742\n",
      "Epoch 2: val_accuracy improved from 0.44437 to 0.45620, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 59s 322ms/step - loss: 1.1933 - accuracy: 0.5742 - val_loss: 1.5214 - val_accuracy: 0.4562\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.1247 - accuracy: 0.5999\n",
      "Epoch 3: val_accuracy improved from 0.45620 to 0.48319, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 59s 324ms/step - loss: 1.1247 - accuracy: 0.5999 - val_loss: 1.5444 - val_accuracy: 0.4832\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.6186\n",
      "Epoch 4: val_accuracy improved from 0.48319 to 0.49065, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 58s 318ms/step - loss: 1.0745 - accuracy: 0.6186 - val_loss: 1.6155 - val_accuracy: 0.4906\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.6289\n",
      "Epoch 5: val_accuracy did not improve from 0.49065\n",
      "181/181 [==============================] - 59s 324ms/step - loss: 1.0429 - accuracy: 0.6289 - val_loss: 1.9508 - val_accuracy: 0.2894\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0183 - accuracy: 0.6405\n",
      "Epoch 6: val_accuracy did not improve from 0.49065\n",
      "181/181 [==============================] - 61s 338ms/step - loss: 1.0183 - accuracy: 0.6405 - val_loss: 1.9984 - val_accuracy: 0.4450\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9976 - accuracy: 0.6463\n",
      "Epoch 7: val_accuracy did not improve from 0.49065\n",
      "181/181 [==============================] - 57s 312ms/step - loss: 0.9976 - accuracy: 0.6463 - val_loss: 1.5223 - val_accuracy: 0.4805\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9808 - accuracy: 0.6537\n",
      "Epoch 8: val_accuracy did not improve from 0.49065\n",
      "181/181 [==============================] - 60s 329ms/step - loss: 0.9808 - accuracy: 0.6537 - val_loss: 1.5473 - val_accuracy: 0.4424\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.6577\n",
      "Epoch 9: val_accuracy improved from 0.49065 to 0.54143, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 58s 321ms/step - loss: 0.9629 - accuracy: 0.6577 - val_loss: 1.3341 - val_accuracy: 0.5414\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9484 - accuracy: 0.6651\n",
      "Epoch 10: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 59s 322ms/step - loss: 0.9484 - accuracy: 0.6651 - val_loss: 1.9581 - val_accuracy: 0.3597\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9338 - accuracy: 0.6695\n",
      "Epoch 11: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 58s 317ms/step - loss: 0.9338 - accuracy: 0.6695 - val_loss: 1.5294 - val_accuracy: 0.4758\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9269 - accuracy: 0.6715\n",
      "Epoch 12: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 59s 327ms/step - loss: 0.9269 - accuracy: 0.6715 - val_loss: 1.4454 - val_accuracy: 0.5111\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6764\n",
      "Epoch 13: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 55s 303ms/step - loss: 0.9149 - accuracy: 0.6764 - val_loss: 1.4761 - val_accuracy: 0.4889\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9021 - accuracy: 0.6812\n",
      "Epoch 14: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 58s 318ms/step - loss: 0.9021 - accuracy: 0.6812 - val_loss: 1.4078 - val_accuracy: 0.5386\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8958 - accuracy: 0.6825\n",
      "Epoch 15: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 56s 306ms/step - loss: 0.8958 - accuracy: 0.6825 - val_loss: 1.4710 - val_accuracy: 0.4993\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8870 - accuracy: 0.6860\n",
      "Epoch 16: val_accuracy did not improve from 0.54143\n",
      "181/181 [==============================] - 61s 338ms/step - loss: 0.8870 - accuracy: 0.6860 - val_loss: 1.5152 - val_accuracy: 0.5186\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8742 - accuracy: 0.6891\n",
      "Epoch 17: val_accuracy improved from 0.54143 to 0.55534, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 57s 313ms/step - loss: 0.8742 - accuracy: 0.6891 - val_loss: 1.3554 - val_accuracy: 0.5553\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8677 - accuracy: 0.6915\n",
      "Epoch 18: val_accuracy improved from 0.55534 to 0.56049, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 57s 313ms/step - loss: 0.8677 - accuracy: 0.6915 - val_loss: 1.2722 - val_accuracy: 0.5605\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8622 - accuracy: 0.6943\n",
      "Epoch 19: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 53s 292ms/step - loss: 0.8622 - accuracy: 0.6943 - val_loss: 1.4129 - val_accuracy: 0.5250\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6953\n",
      "Epoch 20: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 58s 318ms/step - loss: 0.8542 - accuracy: 0.6953 - val_loss: 1.4185 - val_accuracy: 0.5223\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8499 - accuracy: 0.6972\n",
      "Epoch 21: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 58s 317ms/step - loss: 0.8499 - accuracy: 0.6972 - val_loss: 1.4327 - val_accuracy: 0.5260\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.7012\n",
      "Epoch 22: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 61s 335ms/step - loss: 0.8404 - accuracy: 0.7012 - val_loss: 1.4371 - val_accuracy: 0.5118\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.7038\n",
      "Epoch 23: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 63s 348ms/step - loss: 0.8313 - accuracy: 0.7038 - val_loss: 1.3873 - val_accuracy: 0.5346\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8293 - accuracy: 0.7055\n",
      "Epoch 24: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 56s 306ms/step - loss: 0.8293 - accuracy: 0.7055 - val_loss: 1.3902 - val_accuracy: 0.5451\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8201 - accuracy: 0.7082\n",
      "Epoch 25: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 59s 322ms/step - loss: 0.8201 - accuracy: 0.7082 - val_loss: 1.4295 - val_accuracy: 0.5320\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8112 - accuracy: 0.7113\n",
      "Epoch 26: val_accuracy did not improve from 0.56049\n",
      "181/181 [==============================] - 63s 344ms/step - loss: 0.8112 - accuracy: 0.7113 - val_loss: 1.4473 - val_accuracy: 0.5261\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8047 - accuracy: 0.7118\n",
      "Epoch 27: val_accuracy improved from 0.56049 to 0.56593, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 56s 305ms/step - loss: 0.8047 - accuracy: 0.7118 - val_loss: 1.3710 - val_accuracy: 0.5659\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8002 - accuracy: 0.7158\n",
      "Epoch 28: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 65s 356ms/step - loss: 0.8002 - accuracy: 0.7158 - val_loss: 1.4977 - val_accuracy: 0.5224\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7956 - accuracy: 0.7171\n",
      "Epoch 29: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 66s 363ms/step - loss: 0.7956 - accuracy: 0.7171 - val_loss: 1.4676 - val_accuracy: 0.5164\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.7199\n",
      "Epoch 30: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 67s 368ms/step - loss: 0.7902 - accuracy: 0.7199 - val_loss: 1.3677 - val_accuracy: 0.5441\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.7205\n",
      "Epoch 31: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 66s 365ms/step - loss: 0.7824 - accuracy: 0.7205 - val_loss: 1.4607 - val_accuracy: 0.5306\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7774 - accuracy: 0.7234\n",
      "Epoch 32: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 66s 363ms/step - loss: 0.7774 - accuracy: 0.7234 - val_loss: 1.3557 - val_accuracy: 0.5520\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7723 - accuracy: 0.7249\n",
      "Epoch 33: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 61s 334ms/step - loss: 0.7723 - accuracy: 0.7249 - val_loss: 1.3457 - val_accuracy: 0.5530\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.7284\n",
      "Epoch 34: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 56s 308ms/step - loss: 0.7621 - accuracy: 0.7284 - val_loss: 1.3685 - val_accuracy: 0.5526\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.7291\n",
      "Epoch 35: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 56s 310ms/step - loss: 0.7587 - accuracy: 0.7291 - val_loss: 1.4794 - val_accuracy: 0.5302\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.7324\n",
      "Epoch 36: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 59s 324ms/step - loss: 0.7485 - accuracy: 0.7324 - val_loss: 1.4700 - val_accuracy: 0.5288\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.7355\n",
      "Epoch 37: val_accuracy did not improve from 0.56593\n",
      "181/181 [==============================] - 59s 327ms/step - loss: 0.7428 - accuracy: 0.7355 - val_loss: 1.4032 - val_accuracy: 0.5390\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.7372\n",
      "Epoch 38: val_accuracy improved from 0.56593 to 0.56694, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 60s 329ms/step - loss: 0.7387 - accuracy: 0.7372 - val_loss: 1.3623 - val_accuracy: 0.5669\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7269 - accuracy: 0.7399\n",
      "Epoch 39: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 60s 332ms/step - loss: 0.7269 - accuracy: 0.7399 - val_loss: 1.4051 - val_accuracy: 0.5411\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.7413\n",
      "Epoch 40: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 59s 326ms/step - loss: 0.7239 - accuracy: 0.7413 - val_loss: 1.5041 - val_accuracy: 0.5308\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.7429\n",
      "Epoch 41: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 57s 313ms/step - loss: 0.7187 - accuracy: 0.7429 - val_loss: 1.4573 - val_accuracy: 0.5302\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.7461\n",
      "Epoch 42: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 97s 537ms/step - loss: 0.7102 - accuracy: 0.7461 - val_loss: 1.6150 - val_accuracy: 0.4951\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.7485\n",
      "Epoch 43: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 48s 266ms/step - loss: 0.7039 - accuracy: 0.7485 - val_loss: 1.5406 - val_accuracy: 0.5209\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.7521\n",
      "Epoch 44: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.6929 - accuracy: 0.7521 - val_loss: 1.5740 - val_accuracy: 0.5223\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7521\n",
      "Epoch 45: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.6932 - accuracy: 0.7521 - val_loss: 1.4811 - val_accuracy: 0.5422\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.7565\n",
      "Epoch 46: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 48s 265ms/step - loss: 0.6826 - accuracy: 0.7565 - val_loss: 1.4847 - val_accuracy: 0.5402\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.7576\n",
      "Epoch 47: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 48s 266ms/step - loss: 0.6740 - accuracy: 0.7576 - val_loss: 1.6505 - val_accuracy: 0.5137\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.7605\n",
      "Epoch 48: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 48s 266ms/step - loss: 0.6696 - accuracy: 0.7605 - val_loss: 1.4662 - val_accuracy: 0.5379\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.7629\n",
      "Epoch 49: val_accuracy did not improve from 0.56694\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.6650 - accuracy: 0.7629 - val_loss: 1.6308 - val_accuracy: 0.5057\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.7641\n",
      "Epoch 50: val_accuracy improved from 0.56694 to 0.58126, saving model to ../models/training/checkpoint/model_1_concept_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 0.6552 - accuracy: 0.7641 - val_loss: 1.3841 - val_accuracy: 0.5813\n",
      "********************** Model training finished! ********************\n",
      "Saving final model to ../models/training/final/model_1_concept_rmsprop_rgb_512_augment_final.h5\n",
      "Saved model.fit training history to ../models/training/history/model_1_concept_rmsprop_rgb_512_augment_history.json\n",
      "########################################################################################\n",
      "##################### Loop has finished for current model file! ########################\n",
      "########################################################################################\n",
      "########################################\n",
      "Using File model_2_best.json to train model!\n",
      "########################################\n",
      "\n",
      "JSON Loaded: {'Conv2D_1': {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}, 'BatchNormalization_1': {}, 'Conv2D_2': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_2': {}, 'MaxPooling2D_1': {'pool_size': 2}, 'Dropout_1': {'rate': 0.25}, 'Conv2D_3': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_3': {}, 'Conv2D_4': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_4': {}, 'MaxPooling2D_2': {'pool_size': 2}, 'Dropout_2': {'rate': 0.25}, 'Conv2D_5': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_5': {}, 'Conv2D_6': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_6': {}, 'MaxPooling2D_3': {'pool_size': 2}, 'Dropout_3': {'rate': 0.25}, 'Flatten': {}, 'Dense_1': {'units': 2048, 'activation': 'relu'}, 'BatchNormalization_7': {}, 'Dropout_4': {'rate': 0.5}, 'Dense_2': {'units': 7, 'activation': 'softmax'}}\n",
      "\n",
      "Creating Sequential Model ...\n",
      "Added Conv2D_1: {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}\n",
      "Added BatchNormalization_1: {}\n",
      "Added Conv2D_2: {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_2: {}\n",
      "Added MaxPooling2D_1: {'pool_size': 2}\n",
      "Added Dropout_1: {'rate': 0.25}\n",
      "Added Conv2D_3: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_3: {}\n",
      "Added Conv2D_4: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_4: {}\n",
      "Added MaxPooling2D_2: {'pool_size': 2}\n",
      "Added Dropout_2: {'rate': 0.25}\n",
      "Added Conv2D_5: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_5: {}\n",
      "Added Conv2D_6: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_6: {}\n",
      "Added MaxPooling2D_3: {'pool_size': 2}\n",
      "Added Dropout_3: {'rate': 0.25}\n",
      "Added Flatten: {}\n",
      "Added Dense_1: {'units': 2048, 'activation': 'relu'}\n",
      "Added BatchNormalization_7: {}\n",
      "Added Dropout_4: {'rate': 0.5}\n",
      "Added Dense_2: {'units': 7, 'activation': 'softmax'}\n",
      "\n",
      "Optimizers to select from: ['adam', 'rmsprop', 'sgd']\n",
      "\n",
      "Selected Optimizer for training: rmsprop\n",
      "Loss function used: categorical_crossentropy\n",
      "Metrics used: [['accuracy']]\n",
      "The model has been compiled, showing summary below!\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 46, 46, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 46, 46, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 23, 23, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 23, 23, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 23, 23, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 23, 23, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 11, 11, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 11, 11, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 11, 11, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 11, 11, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2048)              13109248  \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 2048)              8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14261319 (54.40 MB)\n",
      "Trainable params: 14255495 (54.38 MB)\n",
      "Non-trainable params: 5824 (22.75 KB)\n",
      "_________________________________________________________________\n",
      "Saving plot_model figure of current model layout to ../models/training/diagram/model_2_best_rmsprop_rgb_512_augment_diagram.png\n",
      "\n",
      "Setting up checkpoint file for incremental validation accuracy improvements\n",
      "********************** Model training started! ********************\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 14:28:46.982554: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 0s - loss: 1.7501 - accuracy: 0.4373\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35500, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fox/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 64s 294ms/step - loss: 1.7501 - accuracy: 0.4373 - val_loss: 1.6855 - val_accuracy: 0.3550\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.3172 - accuracy: 0.5554\n",
      "Epoch 2: val_accuracy improved from 0.35500 to 0.40442, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 1.3172 - accuracy: 0.5554 - val_loss: 1.6696 - val_accuracy: 0.4044\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.1916 - accuracy: 0.6011\n",
      "Epoch 3: val_accuracy improved from 0.40442 to 0.49917, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 1.1916 - accuracy: 0.6011 - val_loss: 1.3889 - val_accuracy: 0.4992\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.1290 - accuracy: 0.6204\n",
      "Epoch 4: val_accuracy improved from 0.49917 to 0.53693, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 1.1290 - accuracy: 0.6204 - val_loss: 1.3081 - val_accuracy: 0.5369\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0946 - accuracy: 0.6349\n",
      "Epoch 5: val_accuracy did not improve from 0.53693\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 1.0946 - accuracy: 0.6349 - val_loss: 1.4188 - val_accuracy: 0.5291\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0581 - accuracy: 0.6433\n",
      "Epoch 6: val_accuracy did not improve from 0.53693\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 1.0581 - accuracy: 0.6433 - val_loss: 1.4224 - val_accuracy: 0.5051\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.6538\n",
      "Epoch 7: val_accuracy improved from 0.53693 to 0.55262, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 1.0350 - accuracy: 0.6538 - val_loss: 1.5360 - val_accuracy: 0.5526\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.6586\n",
      "Epoch 8: val_accuracy did not improve from 0.55262\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 1.0177 - accuracy: 0.6586 - val_loss: 1.3984 - val_accuracy: 0.5095\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.6611\n",
      "Epoch 9: val_accuracy did not improve from 0.55262\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 1.0127 - accuracy: 0.6611 - val_loss: 1.3798 - val_accuracy: 0.5186\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9827 - accuracy: 0.6706\n",
      "Epoch 10: val_accuracy did not improve from 0.55262\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.9827 - accuracy: 0.6706 - val_loss: 1.3743 - val_accuracy: 0.5388\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.6721\n",
      "Epoch 11: val_accuracy did not improve from 0.55262\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.9709 - accuracy: 0.6721 - val_loss: 1.3331 - val_accuracy: 0.5458\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9447 - accuracy: 0.6791\n",
      "Epoch 12: val_accuracy improved from 0.55262 to 0.55303, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 278ms/step - loss: 0.9447 - accuracy: 0.6791 - val_loss: 1.2644 - val_accuracy: 0.5530\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9520 - accuracy: 0.6797\n",
      "Epoch 13: val_accuracy did not improve from 0.55303\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.9520 - accuracy: 0.6797 - val_loss: 1.2699 - val_accuracy: 0.5427\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9483 - accuracy: 0.6814\n",
      "Epoch 14: val_accuracy improved from 0.55303 to 0.56143, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.9483 - accuracy: 0.6814 - val_loss: 1.4102 - val_accuracy: 0.5614\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9361 - accuracy: 0.6854\n",
      "Epoch 15: val_accuracy improved from 0.56143 to 0.56635, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.9361 - accuracy: 0.6854 - val_loss: 1.4682 - val_accuracy: 0.5663\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9095 - accuracy: 0.6900\n",
      "Epoch 16: val_accuracy did not improve from 0.56635\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.9095 - accuracy: 0.6900 - val_loss: 1.2337 - val_accuracy: 0.5640\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8925 - accuracy: 0.6964\n",
      "Epoch 17: val_accuracy did not improve from 0.56635\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.8925 - accuracy: 0.6964 - val_loss: 1.3050 - val_accuracy: 0.5606\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.6956\n",
      "Epoch 18: val_accuracy did not improve from 0.56635\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.8817 - accuracy: 0.6956 - val_loss: 1.3103 - val_accuracy: 0.5563\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8751 - accuracy: 0.6982\n",
      "Epoch 19: val_accuracy improved from 0.56635 to 0.57061, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.8751 - accuracy: 0.6982 - val_loss: 1.2571 - val_accuracy: 0.5706\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.6995\n",
      "Epoch 20: val_accuracy did not improve from 0.57061\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.8666 - accuracy: 0.6995 - val_loss: 1.2698 - val_accuracy: 0.5601\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.7019\n",
      "Epoch 21: val_accuracy did not improve from 0.57061\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.8396 - accuracy: 0.7019 - val_loss: 1.2779 - val_accuracy: 0.5549\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8170 - accuracy: 0.7101\n",
      "Epoch 22: val_accuracy did not improve from 0.57061\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.8170 - accuracy: 0.7101 - val_loss: 1.3902 - val_accuracy: 0.5671\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8073 - accuracy: 0.7137\n",
      "Epoch 23: val_accuracy did not improve from 0.57061\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.8073 - accuracy: 0.7137 - val_loss: 1.2507 - val_accuracy: 0.5623\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7996 - accuracy: 0.7152\n",
      "Epoch 24: val_accuracy improved from 0.57061 to 0.58363, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.7996 - accuracy: 0.7152 - val_loss: 1.2133 - val_accuracy: 0.5836\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7188\n",
      "Epoch 25: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.7911 - accuracy: 0.7188 - val_loss: 1.3282 - val_accuracy: 0.5490\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.7206\n",
      "Epoch 26: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.7820 - accuracy: 0.7206 - val_loss: 1.3232 - val_accuracy: 0.5602\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.7235\n",
      "Epoch 27: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.7756 - accuracy: 0.7235 - val_loss: 1.3463 - val_accuracy: 0.5577\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7656 - accuracy: 0.7278\n",
      "Epoch 28: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.7656 - accuracy: 0.7278 - val_loss: 1.2703 - val_accuracy: 0.5811\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.7307\n",
      "Epoch 29: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 51s 279ms/step - loss: 0.7552 - accuracy: 0.7307 - val_loss: 1.2674 - val_accuracy: 0.5775\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.7312\n",
      "Epoch 30: val_accuracy did not improve from 0.58363\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.7533 - accuracy: 0.7312 - val_loss: 1.3277 - val_accuracy: 0.5739\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.7356\n",
      "Epoch 31: val_accuracy improved from 0.58363 to 0.58718, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.7400 - accuracy: 0.7356 - val_loss: 1.2380 - val_accuracy: 0.5872\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.7314\n",
      "Epoch 32: val_accuracy did not improve from 0.58718\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.7509 - accuracy: 0.7314 - val_loss: 1.4318 - val_accuracy: 0.5429\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.7377\n",
      "Epoch 33: val_accuracy improved from 0.58718 to 0.59168, saving model to ../models/training/checkpoint/model_2_best_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.7329 - accuracy: 0.7377 - val_loss: 1.2131 - val_accuracy: 0.5917\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7179 - accuracy: 0.7437\n",
      "Epoch 34: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.7179 - accuracy: 0.7437 - val_loss: 1.3960 - val_accuracy: 0.5611\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.7432\n",
      "Epoch 35: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.7144 - accuracy: 0.7432 - val_loss: 1.2908 - val_accuracy: 0.5664\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.7464\n",
      "Epoch 36: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.7080 - accuracy: 0.7464 - val_loss: 1.2841 - val_accuracy: 0.5772\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.7489\n",
      "Epoch 37: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.6963 - accuracy: 0.7489 - val_loss: 1.3903 - val_accuracy: 0.5586\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.7494\n",
      "Epoch 38: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.6927 - accuracy: 0.7494 - val_loss: 1.3029 - val_accuracy: 0.5758\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.7545\n",
      "Epoch 39: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 51s 279ms/step - loss: 0.6822 - accuracy: 0.7545 - val_loss: 1.3290 - val_accuracy: 0.5791\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.7581\n",
      "Epoch 40: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.6716 - accuracy: 0.7581 - val_loss: 1.3418 - val_accuracy: 0.5798\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.7600\n",
      "Epoch 41: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 51s 280ms/step - loss: 0.6650 - accuracy: 0.7600 - val_loss: 1.7934 - val_accuracy: 0.5758\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7610\n",
      "Epoch 42: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 51s 279ms/step - loss: 0.6595 - accuracy: 0.7610 - val_loss: 1.4074 - val_accuracy: 0.5666\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.7657\n",
      "Epoch 43: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.6508 - accuracy: 0.7657 - val_loss: 1.3546 - val_accuracy: 0.5669\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.7688\n",
      "Epoch 44: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.6410 - accuracy: 0.7688 - val_loss: 1.2946 - val_accuracy: 0.5866\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.7696\n",
      "Epoch 45: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.6388 - accuracy: 0.7696 - val_loss: 1.3783 - val_accuracy: 0.5722\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6273 - accuracy: 0.7719\n",
      "Epoch 46: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.6273 - accuracy: 0.7719 - val_loss: 1.4795 - val_accuracy: 0.5540\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7770\n",
      "Epoch 47: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 81s 432ms/step - loss: 0.6173 - accuracy: 0.7770 - val_loss: 1.3839 - val_accuracy: 0.5732\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6100 - accuracy: 0.7776\n",
      "Epoch 48: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.6100 - accuracy: 0.7776 - val_loss: 1.3924 - val_accuracy: 0.5727\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.7798\n",
      "Epoch 49: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.6078 - accuracy: 0.7798 - val_loss: 1.4688 - val_accuracy: 0.5624\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7828\n",
      "Epoch 50: val_accuracy did not improve from 0.59168\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.5991 - accuracy: 0.7828 - val_loss: 1.4596 - val_accuracy: 0.5675\n",
      "********************** Model training finished! ********************\n",
      "Saving final model to ../models/training/final/model_2_best_rmsprop_rgb_512_augment_final.h5\n",
      "Saved model.fit training history to ../models/training/history/model_2_best_rmsprop_rgb_512_augment_history.json\n",
      "########################################################################################\n",
      "##################### Loop has finished for current model file! ########################\n",
      "########################################################################################\n",
      "########################################\n",
      "Using File model_3_best_nodropout.json to train model!\n",
      "########################################\n",
      "\n",
      "JSON Loaded: {'Conv2D_1': {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}, 'BatchNormalization_1': {}, 'Conv2D_2': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_2': {}, 'MaxPooling2D_1': {'pool_size': 2}, 'Conv2D_3': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_3': {}, 'Conv2D_4': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_4': {}, 'MaxPooling2D_2': {'pool_size': 2}, 'Conv2D_5': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_5': {}, 'Conv2D_6': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'BatchNormalization_6': {}, 'MaxPooling2D_3': {'pool_size': 2}, 'Flatten': {}, 'Dense_1': {'units': 2048, 'activation': 'relu'}, 'BatchNormalization_7': {}, 'Dense_2': {'units': 7, 'activation': 'softmax'}}\n",
      "\n",
      "Creating Sequential Model ...\n",
      "Added Conv2D_1: {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}\n",
      "Added BatchNormalization_1: {}\n",
      "Added Conv2D_2: {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_2: {}\n",
      "Added MaxPooling2D_1: {'pool_size': 2}\n",
      "Added Conv2D_3: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_3: {}\n",
      "Added Conv2D_4: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_4: {}\n",
      "Added MaxPooling2D_2: {'pool_size': 2}\n",
      "Added Conv2D_5: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_5: {}\n",
      "Added Conv2D_6: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added BatchNormalization_6: {}\n",
      "Added MaxPooling2D_3: {'pool_size': 2}\n",
      "Added Flatten: {}\n",
      "Added Dense_1: {'units': 2048, 'activation': 'relu'}\n",
      "Added BatchNormalization_7: {}\n",
      "Added Dense_2: {'units': 7, 'activation': 'softmax'}\n",
      "\n",
      "Optimizers to select from: ['adam', 'rmsprop', 'sgd']\n",
      "\n",
      "Selected Optimizer for training: rmsprop\n",
      "Loss function used: categorical_crossentropy\n",
      "Metrics used: [['accuracy']]\n",
      "The model has been compiled, showing summary below!\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 46, 46, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 46, 46, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 23, 23, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 23, 23, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 23, 23, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 23, 23, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 11, 11, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 11, 11, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 11, 11, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 11, 11, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2048)              13109248  \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 2048)              8192      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14261319 (54.40 MB)\n",
      "Trainable params: 14255495 (54.38 MB)\n",
      "Non-trainable params: 5824 (22.75 KB)\n",
      "_________________________________________________________________\n",
      "Saving plot_model figure of current model layout to ../models/training/diagram/model_3_best_nodropout_rmsprop_rgb_512_augment_diagram.png\n",
      "\n",
      "Setting up checkpoint file for incremental validation accuracy improvements\n",
      "********************** Model training started! ********************\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.6231 - accuracy: 0.4714\n",
      "Epoch 1: val_accuracy improved from -inf to 0.31818, saving model to ../models/training/checkpoint/model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fox/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 57s 289ms/step - loss: 1.6231 - accuracy: 0.4714 - val_loss: 1.9784 - val_accuracy: 0.3182\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.1654 - accuracy: 0.5870\n",
      "Epoch 2: val_accuracy improved from 0.31818 to 0.44300, saving model to ../models/training/checkpoint/model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 1.1654 - accuracy: 0.5870 - val_loss: 1.8059 - val_accuracy: 0.4430\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0598 - accuracy: 0.6258\n",
      "Epoch 3: val_accuracy improved from 0.44300 to 0.50941, saving model to ../models/training/checkpoint/model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 1.0598 - accuracy: 0.6258 - val_loss: 1.4420 - val_accuracy: 0.5094\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.6461\n",
      "Epoch 4: val_accuracy did not improve from 0.50941\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 1.0026 - accuracy: 0.6461 - val_loss: 1.3839 - val_accuracy: 0.5001\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9600 - accuracy: 0.6603\n",
      "Epoch 5: val_accuracy did not improve from 0.50941\n",
      "181/181 [==============================] - 48s 266ms/step - loss: 0.9600 - accuracy: 0.6603 - val_loss: 1.5303 - val_accuracy: 0.4991\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.6736\n",
      "Epoch 6: val_accuracy did not improve from 0.50941\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.9264 - accuracy: 0.6736 - val_loss: 1.4549 - val_accuracy: 0.5073\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8962 - accuracy: 0.6820\n",
      "Epoch 7: val_accuracy improved from 0.50941 to 0.51568, saving model to ../models/training/checkpoint/model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.8962 - accuracy: 0.6820 - val_loss: 1.4401 - val_accuracy: 0.5157\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8711 - accuracy: 0.6918\n",
      "Epoch 8: val_accuracy did not improve from 0.51568\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.8711 - accuracy: 0.6918 - val_loss: 1.5412 - val_accuracy: 0.4915\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8401 - accuracy: 0.7014\n",
      "Epoch 9: val_accuracy improved from 0.51568 to 0.54332, saving model to ../models/training/checkpoint/model_3_best_nodropout_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.8401 - accuracy: 0.7014 - val_loss: 1.3671 - val_accuracy: 0.5433\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8164 - accuracy: 0.7107\n",
      "Epoch 10: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 265ms/step - loss: 0.8164 - accuracy: 0.7107 - val_loss: 1.4605 - val_accuracy: 0.5137\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.7175\n",
      "Epoch 11: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.7949 - accuracy: 0.7175 - val_loss: 1.4772 - val_accuracy: 0.5230\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7693 - accuracy: 0.7249\n",
      "Epoch 12: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.7693 - accuracy: 0.7249 - val_loss: 1.5471 - val_accuracy: 0.5190\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7446 - accuracy: 0.7337\n",
      "Epoch 13: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.7446 - accuracy: 0.7337 - val_loss: 1.5711 - val_accuracy: 0.5080\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7298 - accuracy: 0.7388\n",
      "Epoch 14: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.7298 - accuracy: 0.7388 - val_loss: 1.5488 - val_accuracy: 0.5109\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.7489\n",
      "Epoch 15: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.6969 - accuracy: 0.7489 - val_loss: 1.7812 - val_accuracy: 0.4891\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.7581\n",
      "Epoch 16: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.6741 - accuracy: 0.7581 - val_loss: 1.4623 - val_accuracy: 0.5321\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.7720\n",
      "Epoch 17: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 266ms/step - loss: 0.6392 - accuracy: 0.7720 - val_loss: 1.5113 - val_accuracy: 0.5333\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7794\n",
      "Epoch 18: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 0.6138 - accuracy: 0.7794 - val_loss: 1.7045 - val_accuracy: 0.4906\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7870\n",
      "Epoch 19: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.5956 - accuracy: 0.7870 - val_loss: 1.6010 - val_accuracy: 0.5328\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8010\n",
      "Epoch 20: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 0.5562 - accuracy: 0.8010 - val_loss: 1.6665 - val_accuracy: 0.5091\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8104\n",
      "Epoch 21: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.5269 - accuracy: 0.8104 - val_loss: 1.7447 - val_accuracy: 0.5353\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8205\n",
      "Epoch 22: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.4984 - accuracy: 0.8205 - val_loss: 1.7780 - val_accuracy: 0.5149\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.8304\n",
      "Epoch 23: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.4728 - accuracy: 0.8304 - val_loss: 1.8350 - val_accuracy: 0.5217\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.8443\n",
      "Epoch 24: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.4402 - accuracy: 0.8443 - val_loss: 1.8679 - val_accuracy: 0.5251\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8523\n",
      "Epoch 25: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.4148 - accuracy: 0.8523 - val_loss: 1.7832 - val_accuracy: 0.5263\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8612\n",
      "Epoch 26: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 265ms/step - loss: 0.3870 - accuracy: 0.8612 - val_loss: 1.9475 - val_accuracy: 0.5309\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8708\n",
      "Epoch 27: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.3648 - accuracy: 0.8708 - val_loss: 1.9481 - val_accuracy: 0.5082\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8776\n",
      "Epoch 28: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.3441 - accuracy: 0.8776 - val_loss: 2.1077 - val_accuracy: 0.5290\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8835\n",
      "Epoch 29: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.3309 - accuracy: 0.8835 - val_loss: 2.1777 - val_accuracy: 0.5090\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.8919\n",
      "Epoch 30: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.3052 - accuracy: 0.8919 - val_loss: 2.3110 - val_accuracy: 0.5077\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9009\n",
      "Epoch 31: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.2823 - accuracy: 0.9009 - val_loss: 2.2282 - val_accuracy: 0.5205\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9021\n",
      "Epoch 32: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.2793 - accuracy: 0.9021 - val_loss: 2.2262 - val_accuracy: 0.5310\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9103\n",
      "Epoch 33: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.2577 - accuracy: 0.9103 - val_loss: 2.1746 - val_accuracy: 0.5371\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9150\n",
      "Epoch 34: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.2440 - accuracy: 0.9150 - val_loss: 2.2817 - val_accuracy: 0.5231\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9202\n",
      "Epoch 35: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.2309 - accuracy: 0.9202 - val_loss: 2.4035 - val_accuracy: 0.5375\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9216\n",
      "Epoch 36: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.2233 - accuracy: 0.9216 - val_loss: 2.4143 - val_accuracy: 0.5351\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9273\n",
      "Epoch 37: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.2102 - accuracy: 0.9273 - val_loss: 2.6010 - val_accuracy: 0.5295\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9279\n",
      "Epoch 38: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.2056 - accuracy: 0.9279 - val_loss: 2.6897 - val_accuracy: 0.5109\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9359\n",
      "Epoch 39: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.1880 - accuracy: 0.9359 - val_loss: 2.3547 - val_accuracy: 0.5313\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9383\n",
      "Epoch 40: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.1810 - accuracy: 0.9383 - val_loss: 2.4262 - val_accuracy: 0.5378\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9407\n",
      "Epoch 41: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 264ms/step - loss: 0.1711 - accuracy: 0.9407 - val_loss: 2.6682 - val_accuracy: 0.5201\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9429\n",
      "Epoch 42: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.1675 - accuracy: 0.9429 - val_loss: 2.7025 - val_accuracy: 0.5269\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9461\n",
      "Epoch 43: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.1573 - accuracy: 0.9461 - val_loss: 2.8491 - val_accuracy: 0.5192\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9457\n",
      "Epoch 44: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 48s 264ms/step - loss: 0.1569 - accuracy: 0.9457 - val_loss: 2.7542 - val_accuracy: 0.5243\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9497\n",
      "Epoch 45: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.1465 - accuracy: 0.9497 - val_loss: 2.6760 - val_accuracy: 0.5337\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9514\n",
      "Epoch 46: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.1434 - accuracy: 0.9514 - val_loss: 2.7894 - val_accuracy: 0.5253\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9537\n",
      "Epoch 47: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.1359 - accuracy: 0.9537 - val_loss: 2.9179 - val_accuracy: 0.5252\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9535\n",
      "Epoch 48: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 270ms/step - loss: 0.1369 - accuracy: 0.9535 - val_loss: 2.8253 - val_accuracy: 0.5305\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9538\n",
      "Epoch 49: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.1353 - accuracy: 0.9538 - val_loss: 2.7655 - val_accuracy: 0.5320\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9554\n",
      "Epoch 50: val_accuracy did not improve from 0.54332\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.1315 - accuracy: 0.9554 - val_loss: 2.9469 - val_accuracy: 0.5291\n",
      "********************** Model training finished! ********************\n",
      "Saving final model to ../models/training/final/model_3_best_nodropout_rmsprop_rgb_512_augment_final.h5\n",
      "Saved model.fit training history to ../models/training/history/model_3_best_nodropout_rmsprop_rgb_512_augment_history.json\n",
      "########################################################################################\n",
      "##################### Loop has finished for current model file! ########################\n",
      "########################################################################################\n",
      "########################################\n",
      "Using File model_4_best_nodroupout_nobatchn.json to train model!\n",
      "########################################\n",
      "\n",
      "JSON Loaded: {'Conv2D_1': {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}, 'Conv2D_2': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'MaxPooling2D_1': {'pool_size': 2}, 'Conv2D_3': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Conv2D_4': {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'MaxPooling2D_2': {'pool_size': 2}, 'Conv2D_5': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'Conv2D_6': {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}, 'MaxPooling2D_3': {'pool_size': 2}, 'Flatten': {}, 'Dense_1': {'units': 2048, 'activation': 'relu'}, 'Dense_2': {'units': 7, 'activation': 'softmax'}}\n",
      "\n",
      "Creating Sequential Model ...\n",
      "Added Conv2D_1: {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'input_shape': [48, 48, 3]}\n",
      "Added Conv2D_2: {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added MaxPooling2D_1: {'pool_size': 2}\n",
      "Added Conv2D_3: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Conv2D_4: {'filters': 128, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added MaxPooling2D_2: {'pool_size': 2}\n",
      "Added Conv2D_5: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added Conv2D_6: {'filters': 256, 'kernel_size': 3, 'activation': 'relu', 'padding': 'same'}\n",
      "Added MaxPooling2D_3: {'pool_size': 2}\n",
      "Added Flatten: {}\n",
      "Added Dense_1: {'units': 2048, 'activation': 'relu'}\n",
      "Added Dense_2: {'units': 7, 'activation': 'softmax'}\n",
      "\n",
      "Optimizers to select from: ['adam', 'rmsprop', 'sgd']\n",
      "\n",
      "Selected Optimizer for training: rmsprop\n",
      "Loss function used: categorical_crossentropy\n",
      "Metrics used: [['accuracy']]\n",
      "The model has been compiled, showing summary below!\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 23, 23, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 23, 23, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 11, 11, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 11, 11, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 5, 5, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2048)              13109248  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14249671 (54.36 MB)\n",
      "Trainable params: 14249671 (54.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Saving plot_model figure of current model layout to ../models/training/diagram/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_diagram.png\n",
      "\n",
      "Setting up checkpoint file for incremental validation accuracy improvements\n",
      "********************** Model training started! ********************\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.6259 - accuracy: 0.3379\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35026, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fox/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 50s 269ms/step - loss: 1.6259 - accuracy: 0.3379 - val_loss: 1.5792 - val_accuracy: 0.3503\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.4579 - accuracy: 0.4438\n",
      "Epoch 2: val_accuracy improved from 0.35026 to 0.45632, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 1.4579 - accuracy: 0.4438 - val_loss: 1.4560 - val_accuracy: 0.4563\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.2206 - accuracy: 0.5610\n",
      "Epoch 3: val_accuracy improved from 0.45632 to 0.49497, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 1.2206 - accuracy: 0.5610 - val_loss: 1.4012 - val_accuracy: 0.4950\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.1002 - accuracy: 0.6066\n",
      "Epoch 4: val_accuracy improved from 0.49497 to 0.51503, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 1.1002 - accuracy: 0.6066 - val_loss: 1.3670 - val_accuracy: 0.5150\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.6351\n",
      "Epoch 5: val_accuracy improved from 0.51503 to 0.54261, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 1.0257 - accuracy: 0.6351 - val_loss: 1.2827 - val_accuracy: 0.5426\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9817 - accuracy: 0.6505\n",
      "Epoch 6: val_accuracy did not improve from 0.54261\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.9817 - accuracy: 0.6505 - val_loss: 1.3174 - val_accuracy: 0.5271\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.6630\n",
      "Epoch 7: val_accuracy improved from 0.54261 to 0.54368, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.9475 - accuracy: 0.6630 - val_loss: 1.2884 - val_accuracy: 0.5437\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.9160 - accuracy: 0.6743\n",
      "Epoch 8: val_accuracy improved from 0.54368 to 0.55593, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 49s 268ms/step - loss: 0.9160 - accuracy: 0.6743 - val_loss: 1.2847 - val_accuracy: 0.5559\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8962 - accuracy: 0.6820\n",
      "Epoch 9: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 48s 267ms/step - loss: 0.8962 - accuracy: 0.6820 - val_loss: 1.2807 - val_accuracy: 0.5543\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8722 - accuracy: 0.6890\n",
      "Epoch 10: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 49s 267ms/step - loss: 0.8722 - accuracy: 0.6890 - val_loss: 1.3457 - val_accuracy: 0.5398\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8474 - accuracy: 0.6994\n",
      "Epoch 11: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 49s 269ms/step - loss: 0.8474 - accuracy: 0.6994 - val_loss: 1.3740 - val_accuracy: 0.5404\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.7054\n",
      "Epoch 12: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 49s 271ms/step - loss: 0.8273 - accuracy: 0.7054 - val_loss: 1.3349 - val_accuracy: 0.5530\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.7118\n",
      "Epoch 13: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.8096 - accuracy: 0.7118 - val_loss: 1.3758 - val_accuracy: 0.5363\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7179\n",
      "Epoch 14: val_accuracy did not improve from 0.55593\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.7911 - accuracy: 0.7179 - val_loss: 1.3684 - val_accuracy: 0.5353\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7255\n",
      "Epoch 15: val_accuracy improved from 0.55593 to 0.56587, saving model to ../models/training/checkpoint/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_cpt.h5\n",
      "181/181 [==============================] - 51s 279ms/step - loss: 0.7672 - accuracy: 0.7255 - val_loss: 1.2737 - val_accuracy: 0.5659\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7492 - accuracy: 0.7337\n",
      "Epoch 16: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 53s 292ms/step - loss: 0.7492 - accuracy: 0.7337 - val_loss: 1.4298 - val_accuracy: 0.5309\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.7427\n",
      "Epoch 17: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.7239 - accuracy: 0.7427 - val_loss: 1.4262 - val_accuracy: 0.5500\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.7499\n",
      "Epoch 18: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.7006 - accuracy: 0.7499 - val_loss: 1.3882 - val_accuracy: 0.5516\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.7587\n",
      "Epoch 19: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.6763 - accuracy: 0.7587 - val_loss: 1.4987 - val_accuracy: 0.5348\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7670\n",
      "Epoch 20: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.6553 - accuracy: 0.7670 - val_loss: 1.4853 - val_accuracy: 0.5407\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7725\n",
      "Epoch 21: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.6355 - accuracy: 0.7725 - val_loss: 1.5700 - val_accuracy: 0.5264\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.7836\n",
      "Epoch 22: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.6041 - accuracy: 0.7836 - val_loss: 1.5375 - val_accuracy: 0.5329\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5848 - accuracy: 0.7905\n",
      "Epoch 23: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 51s 282ms/step - loss: 0.5848 - accuracy: 0.7905 - val_loss: 1.5767 - val_accuracy: 0.5413\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7982\n",
      "Epoch 24: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 49s 273ms/step - loss: 0.5606 - accuracy: 0.7982 - val_loss: 1.6137 - val_accuracy: 0.5369\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8092\n",
      "Epoch 25: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.5330 - accuracy: 0.8092 - val_loss: 1.6067 - val_accuracy: 0.5384\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.8168\n",
      "Epoch 26: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.5110 - accuracy: 0.8168 - val_loss: 1.7236 - val_accuracy: 0.5285\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.8233\n",
      "Epoch 27: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.4906 - accuracy: 0.8233 - val_loss: 1.7978 - val_accuracy: 0.5318\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.8328\n",
      "Epoch 28: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.4664 - accuracy: 0.8328 - val_loss: 1.8256 - val_accuracy: 0.5264\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8379\n",
      "Epoch 29: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.4517 - accuracy: 0.8379 - val_loss: 1.8902 - val_accuracy: 0.5288\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8479\n",
      "Epoch 30: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.4288 - accuracy: 0.8479 - val_loss: 1.9765 - val_accuracy: 0.5194\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.8533\n",
      "Epoch 31: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.4123 - accuracy: 0.8533 - val_loss: 2.1091 - val_accuracy: 0.5163\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8601\n",
      "Epoch 32: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.3965 - accuracy: 0.8601 - val_loss: 1.9179 - val_accuracy: 0.5219\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8639\n",
      "Epoch 33: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 278ms/step - loss: 0.3824 - accuracy: 0.8639 - val_loss: 2.1654 - val_accuracy: 0.5037\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8700\n",
      "Epoch 34: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 273ms/step - loss: 0.3658 - accuracy: 0.8700 - val_loss: 2.2203 - val_accuracy: 0.5014\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8737\n",
      "Epoch 35: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 274ms/step - loss: 0.3575 - accuracy: 0.8737 - val_loss: 2.2097 - val_accuracy: 0.5197\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8779\n",
      "Epoch 36: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.3406 - accuracy: 0.8779 - val_loss: 2.2945 - val_accuracy: 0.5230\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8842\n",
      "Epoch 37: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.3276 - accuracy: 0.8842 - val_loss: 2.2529 - val_accuracy: 0.5128\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.8881\n",
      "Epoch 38: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.3141 - accuracy: 0.8881 - val_loss: 2.3372 - val_accuracy: 0.5299\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8933\n",
      "Epoch 39: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.3032 - accuracy: 0.8933 - val_loss: 2.3990 - val_accuracy: 0.5178\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.8972\n",
      "Epoch 40: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.2933 - accuracy: 0.8972 - val_loss: 2.3560 - val_accuracy: 0.5140\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8963\n",
      "Epoch 41: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.2909 - accuracy: 0.8963 - val_loss: 2.4118 - val_accuracy: 0.5218\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.9040\n",
      "Epoch 42: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 276ms/step - loss: 0.2711 - accuracy: 0.9040 - val_loss: 2.4746 - val_accuracy: 0.5154\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9059\n",
      "Epoch 43: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.2687 - accuracy: 0.9059 - val_loss: 2.5863 - val_accuracy: 0.5269\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9092\n",
      "Epoch 44: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.2573 - accuracy: 0.9092 - val_loss: 2.5095 - val_accuracy: 0.5235\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9127\n",
      "Epoch 45: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 278ms/step - loss: 0.2491 - accuracy: 0.9127 - val_loss: 2.5310 - val_accuracy: 0.5134\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9156\n",
      "Epoch 46: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 49s 273ms/step - loss: 0.2395 - accuracy: 0.9156 - val_loss: 2.6600 - val_accuracy: 0.5214\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9160\n",
      "Epoch 47: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 277ms/step - loss: 0.2373 - accuracy: 0.9160 - val_loss: 2.5537 - val_accuracy: 0.5187\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9197\n",
      "Epoch 48: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 275ms/step - loss: 0.2297 - accuracy: 0.9197 - val_loss: 2.7314 - val_accuracy: 0.5090\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9209\n",
      "Epoch 49: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 49s 272ms/step - loss: 0.2238 - accuracy: 0.9209 - val_loss: 2.7363 - val_accuracy: 0.5295\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9236\n",
      "Epoch 50: val_accuracy did not improve from 0.56587\n",
      "181/181 [==============================] - 50s 278ms/step - loss: 0.2187 - accuracy: 0.9236 - val_loss: 2.7447 - val_accuracy: 0.5327\n",
      "********************** Model training finished! ********************\n",
      "Saving final model to ../models/training/final/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_final.h5\n",
      "Saved model.fit training history to ../models/training/history/model_4_best_nodroupout_nobatchn_rmsprop_rgb_512_augment_history.json\n",
      "########################################################################################\n",
      "##################### Loop has finished for current model file! ########################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "# Specify the path to the folder containing your JSON files\n",
    "folder_path = '../models/'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter only JSON files\n",
    "json_files = sorted([file for file in files if file.endswith('.json')])\n",
    "print(f'Found JSON config files in models: {json_files}\\n')\n",
    "\n",
    "# Iterate through the JSON files and load them\n",
    "for json_file in json_files:\n",
    "    json_file_path = os.path.join(folder_path, json_file)\n",
    "    \n",
    "    print(f'########################################')\n",
    "    print(f'Using File {json_file} to train model!')\n",
    "    print(f'########################################\\n')\n",
    "\n",
    "    with open(json_file_path,mode='r') as file:\n",
    "        m = json.load(file)\n",
    "        print('JSON Loaded:',m)\n",
    "        print()\n",
    "\n",
    "        # Patching first layer with input to be aligned with the image_depth (e.g. if using grayscale vs rgb)\n",
    "        m['Conv2D_1']['input_shape'] = [48,48,image_depth]\n",
    "\n",
    "        # Initializating the model from JSON configuration\n",
    "        # Step 1 - Create Sequential model\n",
    "        print('Creating Sequential Model ...')\n",
    "        model = Sequential()\n",
    "\n",
    "        # Step 2 - Iteratively add the configured layers and their parameters\n",
    "        for layer_name, layer_config in m.items():\n",
    "            layer_type = layer_name.split(\"_\")[0]\n",
    "            print(f\"Added {layer_name}: {layer_config}\")\n",
    "\n",
    "            # Add layers based on layer type\n",
    "            if layer_type == 'Conv2D':\n",
    "                model.add(Conv2D(**layer_config))\n",
    "            elif layer_type == 'MaxPooling2D':\n",
    "                model.add(MaxPooling2D(**layer_config))\n",
    "            elif layer_type == 'Flatten':\n",
    "                model.add(Flatten(**layer_config))\n",
    "            elif layer_type == 'Dense':\n",
    "                model.add(Dense(**layer_config))\n",
    "            elif layer_type == 'BatchNormalization':\n",
    "                model.add(BatchNormalization(**layer_config))\n",
    "            elif layer_type == 'Dropout':\n",
    "                model.add(Dropout(**layer_config))\n",
    "            else:\n",
    "                # Handle unrecognized layer types or raise an exception\n",
    "                raise ValueError(f\"Unsupported layer type: {layer_type}\")\n",
    "        \n",
    "        # Step 3 - Optimizer Values\n",
    "        optimizer = {\n",
    "            'adam': tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "            'rmsprop': tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "            'sgd': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "        }\n",
    "        print(f\"\\nOptimizers to select from: {list(optimizer.keys())}\")\n",
    "        selected_optimizer = 'rmsprop'\n",
    "        print(f\"\\nSelected Optimizer for training: {selected_optimizer}\")\n",
    "\n",
    "        # Step 4 - Loss function\n",
    "        loss = 'categorical_crossentropy'\n",
    "        print(f\"Loss function used: {loss}\")\n",
    "\n",
    "        # Step 5 - Metrics\n",
    "        metrics = ['accuracy']\n",
    "        print(f\"Metrics used: [{metrics}]\")\n",
    "        \n",
    "        # Compile the model with settings\n",
    "        model.compile(\n",
    "            optimizer=optimizer['adam'],\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        print('The model has been compiled, showing summary below!\\n')\n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "\n",
    "        # Save the visual diagram to an image file (e.g., PNG)\n",
    "        # Model architecture remains the same, so we can store them all under one file_name for each different model (model_1_concept, model_2_best, model_3_best_nodropout ...)\n",
    "        diagram_filename = folder_path + f\"training/diagram/{json_file.split('.')[0]}_diagram.png\"\n",
    "        print(f'Saving plot_model figure of current model layout to {diagram_filename}')\n",
    "        plot_model(model, to_file=diagram_filename, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        # Start model training!\n",
    "        # Define hyperparameters\n",
    "        checkpoint_filename = folder_path+f\"training/checkpoint/{json_file.split('.')[0]}_{selected_optimizer}_{image_color_mode}_{batch_size}_{augment}_cpt.h5\"\n",
    "        epochs = 50\n",
    "        monitor='val_accuracy'\n",
    "        mode='max'\n",
    "\n",
    "        # Set up model checkpoint\n",
    "        print('\\nSetting up checkpoint file for incremental validation accuracy improvements')\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_filename,\n",
    "            monitor=monitor,\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode=mode\n",
    "        )\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        # Train the model\n",
    "        print(f'********************** Model training started! ********************')\n",
    "        history = model.fit(\n",
    "            train_set,\n",
    "            validation_data=test_set,\n",
    "            steps_per_epoch=total_images_train // batch_size,\n",
    "            validation_steps=total_images_test // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "        print(f'********************** Model training finished! ********************')\n",
    "\n",
    "        # Saving final model after train epochs have completed\n",
    "        final_filename = folder_path+f\"training/final/{json_file.split('.')[0]}_{selected_optimizer}_{image_color_mode}_{batch_size}_{augment}_final.h5\"\n",
    "        print(f'Saving final model to {final_filename}')\n",
    "        model.save_weights(final_filename)\n",
    "\n",
    "        # Saving training history to file\n",
    "        history_filename = folder_path+f\"training/history/{json_file.split('.')[0]}_{selected_optimizer}_{image_color_mode}_{batch_size}_{augment}_history.json\"\n",
    "        with open(history_filename, 'w') as history_file:\n",
    "            json.dump(history.history, history_file)\n",
    "            print(f'Saved model.fit training history to {history_filename}')\n",
    "\n",
    "        # End of training loop!\n",
    "        print('########################################################################################')\n",
    "        print('##################### Loop has finished for current model file! ########################')\n",
    "        print('########################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
